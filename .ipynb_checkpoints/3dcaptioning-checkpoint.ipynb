{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas \n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import operator\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from data import *\n",
    "from constants import *\n",
    "from models import *\n",
    "from solver import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/mnt/raid/davech2y/3d_captioning/ShapeNetCore_vol/nrrd_256_filter_div_128_solid/\"\n",
    "captions = pandas.read_csv(\"captions.tablechair.csv\").iloc[:600]\n",
    "visual_contexts = np.load(\"data/visual_context.npy\")\n",
    "# captions = pandas.read_csv(\"captions.tablechair_prep.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions = Caption(captions)\n",
    "captions.preprocess()\n",
    "captions.tranform()\n",
    "captions.sanity_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_captions = captions.tranformed_csv.iloc[:500]\n",
    "valid_captions = captions.tranformed_csv.iloc[500:600].reset_index(drop=True)\n",
    "train_context = visual_contexts[:500]\n",
    "valid_context = visual_contexts[500:600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape_tranform = transforms.Compose([transforms.Resize(IMAGE_SIZE), transforms.ToTensor()])\n",
    "# shape_train_ds = ShapeDataset(root, train_captions, shape_tranform)\n",
    "# shape_train_dl = DataLoader(shape_train_ds, batch_size=10)\n",
    "# shape_valid_ds = ShapeDataset(root, valid_captions, shape_tranform)\n",
    "# shape_valid_dl = DataLoader(shape_valid_ds, batch_size=10)\n",
    "# shape_dl = {\n",
    "#     'train': shape_train_dl,\n",
    "#     'valid': shape_valid_dl\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Encoder().cuda()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# encoder_solver = EncoderSolver(optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# encoder_solver.train(model, shape_dl, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = captions.dict_word2idx.__len__() + 1\n",
    "hidden_size = 512\n",
    "decoder = Decoder(input_size, hidden_size).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_train_ds = CaptionDataset(train_context, train_captions.description.values.tolist())\n",
    "caption_train_dl = DataLoader(caption_train_ds, batch_size=50, shuffle=False)\n",
    "caption_valid_ds = CaptionDataset(valid_context, valid_captions.description.values.tolist())\n",
    "caption_valid_dl = DataLoader(caption_valid_ds, batch_size=50, shuffle=False)\n",
    "caption_dl = {\n",
    "    \"train\": caption_train_dl,\n",
    "    \"valid\": caption_valid_dl\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_solver = DecoderSolver(optim.RMSprop(decoder.parameters(), lr=0.001), nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1000/10000] train_loss: 5.649673, valid_loss: 6.253466\n",
      "[epoch 2000/10000] train_loss: 5.646488, valid_loss: 6.273619\n",
      "[epoch 3000/10000] train_loss: 5.644440, valid_loss: 6.276175\n",
      "[epoch 4000/10000] train_loss: 5.652386, valid_loss: 6.298085\n",
      "[epoch 5000/10000] train_loss: 5.642811, valid_loss: 6.302113\n",
      "[epoch 6000/10000] train_loss: 5.642381, valid_loss: 6.302835\n",
      "[epoch 7000/10000] train_loss: 5.641885, valid_loss: 6.298961\n",
      "[epoch 8000/10000] train_loss: 5.642154, valid_loss: 6.280963\n",
      "[epoch 9000/10000] train_loss: 5.642382, valid_loss: 6.283738\n",
      "[epoch 10000/10000] train_loss: 5.641955, valid_loss: 6.298563\n"
     ]
    }
   ],
   "source": [
    "decoder_solver.train(decoder, caption_dl, 10000, 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
