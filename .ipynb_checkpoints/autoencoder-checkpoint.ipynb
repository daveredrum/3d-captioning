{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas \n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import operator\n",
    "import math\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from constants import *\n",
    "from data import *\n",
    "from encoders import *\n",
    "from decoders import *\n",
    "from solver import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as torchmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 10\n",
    "valid_size = 10\n",
    "batch_size = 2\n",
    "coco = COCO(\n",
    "    pandas.read_csv(\"/mnt/raid/davech2y/COCO_2014/preprocessed/coco_train2014.caption.csv\"), \n",
    "#     pandas.read_csv(\"/mnt/raid/davech2y/COCO_2014/preprocessed/coco_train2014.caption.csv\"), \n",
    "    pandas.read_csv(\"/mnt/raid/davech2y/COCO_2014/preprocessed/coco_valid2014.caption.csv\"),\n",
    "    [train_size, valid_size]\n",
    ")\n",
    "train_captions = coco.transformed_data['train']\n",
    "valid_captions = coco.transformed_data['valid']\n",
    "dict_idx2word = coco.dict_idx2word\n",
    "dict_word2idx = coco.dict_word2idx\n",
    "corpus = coco.corpus\n",
    "train_ds = COCOCaptionDataset(\n",
    "    None,\n",
    "    train_captions, \n",
    "    database=\"/mnt/raid/davech2y/COCO_2014/preprocessed/coco_train2014_224_new.hdf5\"\n",
    ")\n",
    "valid_ds = COCOCaptionDataset(\n",
    "    None, \n",
    "    valid_captions,\n",
    "    database=\"/mnt/raid/davech2y/COCO_2014/preprocessed/coco_valid2014_224_new.hdf5\"\n",
    "#     database=\"/mnt/raid/davech2y/COCO_2014/preprocessed/coco_train2014_224_new.hdf5\"\n",
    ")\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)\n",
    "dataloader = {\n",
    "    'train': train_dl,\n",
    "    'valid': valid_dl\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, dict_size):\n",
    "        super(AttnAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 3, kernel_size=2, stride=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, inputs, caption_inputs):\n",
    "        visual_encoded = self.encoder(inputs)\n",
    "        outputs = self.decoder(visual_encoded)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE_skip(nn.Module):\n",
    "    def __init__(self, dict_size):\n",
    "        super(AttnAE, self).__init__()\n",
    "        self.encoder_1 = nn.Sequential(\n",
    "            # (3, 224, 224)\n",
    "            nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.encoder_2 = nn.Sequential(\n",
    "            # (8, 112, 112)\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.encoder_3 = nn.Sequential(\n",
    "            # (16, 56, 56)\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.encoder_4 = nn.Sequential(\n",
    "            # (32, 28, 28)\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # (64, 14, 14)\n",
    "        )\n",
    "        self.encoder_5 = nn.Sequential( \n",
    "            # (64, 14, 14)\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            # (128, 7, 7)\n",
    "        )\n",
    "\n",
    "        self.decoder_1 = nn.Sequential(\n",
    "            # (128, 7, 7)\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            # (64, 14, 14)\n",
    "        )\n",
    "        self.decoder_2 = nn.Sequential(    \n",
    "            # (128, 14, 14)\n",
    "            nn.ConvTranspose2d(128, 32, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            # (32, 28, 28)\n",
    "        )\n",
    "        self.decoder_3 = nn.Sequential(\n",
    "            # (64, 28, 28)\n",
    "            nn.ConvTranspose2d(64, 16, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            # (16, 56, 56)\n",
    "        )\n",
    "        self.decoder_4 = nn.Sequential(\n",
    "            # (32, 56, 56)\n",
    "            nn.ConvTranspose2d(32, 8, kernel_size=2, stride=2),\n",
    "            nn.ReLU()\n",
    "            # (8, 112, 112)\n",
    "        )\n",
    "        self.decoder_5 = nn.Sequential(\n",
    "            # (8, 112, 112)\n",
    "            nn.ConvTranspose2d(16, 3, kernel_size=2, stride=2),\n",
    "            nn.ReLU()\n",
    "            # (3, 224, 224)\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def forward(self, inputs, caption_inputs):\n",
    "        encoded_1 = self.encoder_1(inputs)\n",
    "        encoded_2 = self.encoder_2(encoded_1)\n",
    "        encoded_3 = self.encoder_3(encoded_2)\n",
    "        encoded_4 = self.encoder_4(encoded_3)\n",
    "        encoded_5 = self.encoder_5(encoded_4)\n",
    "        decoded_1 = self.decoder_1(encoded_5)\n",
    "        decoded_2 = self.decoder_2(torch.cat((decoded_1, encoded_4), dim=1))\n",
    "        decoded_3 = self.decoder_3(torch.cat((decoded_2, encoded_3), dim=1))\n",
    "        decoded_4 = self.decoder_4(torch.cat((decoded_3, encoded_2), dim=1))\n",
    "        outputs = self.decoder_5(torch.cat((decoded_4, encoded_1), dim=1))\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnAE(nn.Module):\n",
    "    def __init__(self, dict_size):\n",
    "        super(AttnAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 3, kernel_size=2, stride=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.comp_visual = nn.Linear(256, 512)\n",
    "        self.comp_hidden = nn.Linear(512, 512)\n",
    "        self.attn_combine = nn.Linear(512, 1)\n",
    "        self.embedding = nn.Embedding(dict_size, 512)\n",
    "        self.text_encoder = nn.LSTMCell(512, 512)\n",
    "    \n",
    "    def initHidden(self, visual_encoded):\n",
    "        states = (\n",
    "            Variable(torch.zeros(visual_encoded.size(0), 512)),\n",
    "            Variable(torch.zeros(visual_encoded.size(0), 512))\n",
    "        )\n",
    "        \n",
    "        return states\n",
    "    \n",
    "    def attention(self, visual_encoded, hiddens):\n",
    "        inputs = visual_encoded.view(visual_encoded.size(0), visual_encoded.size(1), -1)\n",
    "        inputs = inputs.transpose(2, 1).contiguous()\n",
    "        V = self.comp_visual(inputs)\n",
    "        H = self.comp_hidden(hiddens).unsqueeze(1)\n",
    "        outputs = F.tanh(V + H)\n",
    "        outputs = self.attn_combine(outputs).squeeze()\n",
    "        outputs = F.softmax(outputs, dim=1)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def forward(self, inputs, caption_inputs):\n",
    "        visual_encoded = self.encoder(inputs)\n",
    "        states = self.initHidden(visual_encoded)\n",
    "        seq_length = caption_inputs.size(1)\n",
    "        attn_inputs = []\n",
    "        for step in range(seq_length):\n",
    "            embedded = self.embedding(caption_inputs[:, step])\n",
    "            states = self.text_encoder(embedded, states)\n",
    "            attn_inputs.append(states[0].unsqueeze(1))\n",
    "        attn_inputs = torch.cat(attn_inputs, dim=1)\n",
    "        attn_inputs = attn_inputs.mean(1)\n",
    "        attn_weights = self.attention(visual_encoded, attn_inputs)\n",
    "        attended = visual_encoded.view(visual_encoded.size(0), visual_encoded.size(1), -1) * attn_weights.unsqueeze(1)\n",
    "        outputs = self.decoder(attended.view(attended.size(0), attended.size(1), int(np.sqrt(attended.size(2))), int(np.sqrt(attended.size(2)))))\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AE(dict_idx2word.__len__() + 1)\n",
    "cr = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.4731552600860596\n",
      "loss: 1.4684765338897705\n",
      "loss: 1.4642805337905884\n",
      "loss: 1.4601991653442383\n",
      "loss: 1.455910849571228\n",
      "loss: 1.4514995574951173\n",
      "loss: 1.4465100049972535\n",
      "loss: 1.4355175018310546\n",
      "loss: 1.311687970161438\n",
      "loss: 1.1681266188621522\n",
      "loss: 1.1369916200637817\n",
      "loss: 1.0546221375465392\n",
      "loss: 1.0198426604270936\n",
      "loss: 0.9784405827522278\n",
      "loss: 0.9332048296928406\n",
      "loss: 0.9131057739257813\n",
      "loss: 0.9004910826683045\n",
      "loss: 0.8944319009780883\n",
      "loss: 0.8956144094467163\n",
      "loss: 0.8869249224662781\n",
      "loss: 0.8753095030784607\n",
      "loss: 0.8689142942428589\n",
      "loss: 0.8660258650779724\n",
      "loss: 0.8594482421875\n",
      "loss: 0.8554783463478088\n",
      "loss: 0.8501441597938537\n",
      "loss: 0.8411869883537293\n",
      "loss: 0.8266507148742676\n",
      "loss: 0.8190279364585876\n",
      "loss: 0.798250138759613\n",
      "loss: 0.7715648531913757\n",
      "loss: 0.7178617238998413\n",
      "loss: 0.6668466567993164\n",
      "loss: 0.6422518968582154\n",
      "loss: 0.61940438747406\n",
      "loss: 0.6143876433372497\n",
      "loss: 0.5965945899486542\n",
      "loss: 0.5900753378868103\n",
      "loss: 0.5881588578224182\n",
      "loss: 0.5769123315811158\n",
      "loss: 0.5740221619606019\n",
      "loss: 0.5613868653774261\n",
      "loss: 0.5511614382266998\n",
      "loss: 0.5451028704643249\n",
      "loss: 0.5394796133041382\n",
      "loss: 0.5353594720363617\n",
      "loss: 0.535459178686142\n",
      "loss: 0.5273380696773529\n",
      "loss: 0.5273214638233185\n",
      "loss: 0.5237328469753265\n",
      "loss: 0.5172037601470947\n",
      "loss: 0.5134107768535614\n",
      "loss: 0.5175478100776673\n",
      "loss: 0.5084162592887879\n",
      "loss: 0.5136561930179596\n",
      "loss: 0.5335480093955993\n",
      "loss: 0.518042916059494\n",
      "loss: 0.5219272494316101\n",
      "loss: 0.5257004022598266\n",
      "loss: 0.4977895438671112\n",
      "loss: 0.49560169577598573\n",
      "loss: 0.49986734986305237\n",
      "loss: 0.4945658564567566\n",
      "loss: 0.4945161044597626\n",
      "loss: 0.48243050575256347\n",
      "loss: 0.4779533326625824\n",
      "loss: 0.4732516348361969\n",
      "loss: 0.4740832567214966\n",
      "loss: 0.4680555462837219\n",
      "loss: 0.4702721834182739\n",
      "loss: 0.4648790180683136\n",
      "loss: 0.4615197479724884\n",
      "loss: 0.4588358163833618\n",
      "loss: 0.4586719572544098\n",
      "loss: 0.4601096034049988\n",
      "loss: 0.4524086952209473\n",
      "loss: 0.4495711803436279\n",
      "loss: 0.4472451269626617\n",
      "loss: 0.4456358253955841\n",
      "loss: 0.4430192232131958\n",
      "loss: 0.44528680443763735\n",
      "loss: 0.45135573148727415\n",
      "loss: 0.4562315821647644\n",
      "loss: 0.46202380657196046\n",
      "loss: 0.4428858458995819\n",
      "loss: 0.44224196672439575\n",
      "loss: 0.43641276359558107\n",
      "loss: 0.43567708134651184\n",
      "loss: 0.43328015208244325\n",
      "loss: 0.4289886474609375\n",
      "loss: 0.4316220462322235\n",
      "loss: 0.42541962265968325\n",
      "loss: 0.4233708679676056\n",
      "loss: 0.4227622628211975\n",
      "loss: 0.42338021993637087\n",
      "loss: 0.4265002369880676\n",
      "loss: 0.41991361379623415\n",
      "loss: 0.41928577423095703\n",
      "loss: 0.42069711685180666\n",
      "loss: 0.41335992217063905\n",
      "loss: 0.41477500200271605\n",
      "loss: 0.413764089345932\n",
      "loss: 0.40999128818511965\n",
      "loss: 0.40896405577659606\n",
      "loss: 0.40894126892089844\n",
      "loss: 0.40678760409355164\n",
      "loss: 0.40336652398109435\n",
      "loss: 0.40211166739463805\n",
      "loss: 0.4093681573867798\n",
      "loss: 0.4124762713909149\n",
      "loss: 0.40414588451385497\n",
      "loss: 0.4036456525325775\n",
      "loss: 0.40532790422439574\n",
      "loss: 0.40104809403419495\n",
      "loss: 0.406950855255127\n",
      "loss: 0.39656177163124084\n",
      "loss: 0.39275164604187013\n",
      "loss: 0.39061870574951174\n",
      "loss: 0.390993469953537\n",
      "loss: 0.39081851840019227\n",
      "loss: 0.38671267628669737\n",
      "loss: 0.3869093120098114\n",
      "loss: 0.3843082845211029\n",
      "loss: 0.3827300727367401\n",
      "loss: 0.38059449195861816\n",
      "loss: 0.3831209361553192\n",
      "loss: 0.38527345657348633\n",
      "loss: 0.3808256685733795\n",
      "loss: 0.3813648998737335\n",
      "loss: 0.3860322117805481\n",
      "loss: 0.3873919308185577\n",
      "loss: 0.3794716775417328\n",
      "loss: 0.3836387276649475\n",
      "loss: 0.39541024565696714\n",
      "loss: 0.3974051296710968\n",
      "loss: 0.4010082185268402\n",
      "loss: 0.3839980125427246\n",
      "loss: 0.3905592381954193\n",
      "loss: 0.3820095479488373\n",
      "loss: 0.37592201828956606\n",
      "loss: 0.37075750827789306\n",
      "loss: 0.3693671584129333\n",
      "loss: 0.3668670654296875\n",
      "loss: 0.36732337474822996\n",
      "loss: 0.3677835762500763\n",
      "loss: 0.3658653795719147\n",
      "loss: 0.3612779021263123\n",
      "loss: 0.35916581749916077\n",
      "loss: 0.3607890546321869\n",
      "loss: 0.3602411150932312\n",
      "loss: 0.3574815332889557\n",
      "loss: 0.35688554048538207\n",
      "loss: 0.3572599649429321\n",
      "loss: 0.35581361055374144\n",
      "loss: 0.3548363268375397\n",
      "loss: 0.3547917366027832\n",
      "loss: 0.35852203965187074\n",
      "loss: 0.3597594380378723\n",
      "loss: 0.3553455948829651\n",
      "loss: 0.3548493981361389\n",
      "loss: 0.35937639474868777\n",
      "loss: 0.3579754889011383\n",
      "loss: 0.35254380106925964\n",
      "loss: 0.35379462242126464\n",
      "loss: 0.3582051992416382\n",
      "loss: 0.356380820274353\n",
      "loss: 0.3494633734226227\n",
      "loss: 0.3532884418964386\n",
      "loss: 0.3550437390804291\n",
      "loss: 0.3497011959552765\n",
      "loss: 0.3521023392677307\n",
      "loss: 0.3438765168190002\n",
      "loss: 0.34300151467323303\n",
      "loss: 0.3440935373306274\n",
      "loss: 0.34193503856658936\n",
      "loss: 0.3379840612411499\n",
      "loss: 0.3383086800575256\n",
      "loss: 0.3406044542789459\n",
      "loss: 0.3398595452308655\n",
      "loss: 0.33705312609672544\n",
      "loss: 0.34071165323257446\n",
      "loss: 0.34214612245559695\n",
      "loss: 0.3391324758529663\n",
      "loss: 0.34386917352676394\n",
      "loss: 0.3383993446826935\n",
      "loss: 0.33920063972473147\n",
      "loss: 0.3391323149204254\n",
      "loss: 0.339883828163147\n",
      "loss: 0.33430603742599485\n",
      "loss: 0.33664711117744445\n",
      "loss: 0.33638428449630736\n",
      "loss: 0.3378484308719635\n",
      "loss: 0.33551023006439207\n",
      "loss: 0.337736701965332\n",
      "loss: 0.339405882358551\n",
      "loss: 0.3335802733898163\n",
      "loss: 0.33342514634132386\n",
      "loss: 0.3328270196914673\n",
      "loss: 0.32724615931510925\n",
      "loss: 0.32606214880943296\n",
      "loss: 0.3289162516593933\n",
      "loss: 0.3251853585243225\n",
      "loss: 0.3235417604446411\n",
      "loss: 0.32335034012794495\n",
      "loss: 0.3231631100177765\n",
      "loss: 0.3220166742801666\n",
      "loss: 0.3221138119697571\n",
      "loss: 0.32403255105018614\n",
      "loss: 0.32232399582862853\n",
      "loss: 0.3227339148521423\n",
      "loss: 0.32508873343467715\n",
      "loss: 0.3209855675697327\n",
      "loss: 0.31761605143547056\n",
      "loss: 0.3235511898994446\n",
      "loss: 0.3256848454475403\n",
      "loss: 0.3211015522480011\n",
      "loss: 0.3254336893558502\n",
      "loss: 0.3267329096794128\n",
      "loss: 0.3205729365348816\n",
      "loss: 0.32076491713523864\n",
      "loss: 0.3204977333545685\n",
      "loss: 0.31738766431808474\n",
      "loss: 0.3208490550518036\n",
      "loss: 0.31605424284934996\n",
      "loss: 0.3134243667125702\n",
      "loss: 0.3161046028137207\n",
      "loss: 0.3133526802062988\n",
      "loss: 0.31454121470451357\n",
      "loss: 0.31124839186668396\n",
      "loss: 0.30730521082878115\n",
      "loss: 0.31096034646034243\n",
      "loss: 0.31269690990447996\n",
      "loss: 0.3097908854484558\n",
      "loss: 0.31057093739509584\n",
      "loss: 0.31301987171173096\n",
      "loss: 0.3080253481864929\n",
      "loss: 0.3079988658428192\n",
      "loss: 0.30814350843429567\n",
      "loss: 0.3059859722852707\n",
      "loss: 0.31030436754226687\n",
      "loss: 0.3081231236457825\n",
      "loss: 0.3047513723373413\n",
      "loss: 0.3043951213359833\n",
      "loss: 0.30375047624111173\n",
      "loss: 0.30135405957698824\n",
      "loss: 0.30370253026485444\n",
      "loss: 0.300089967250824\n",
      "loss: 0.29833940863609315\n",
      "loss: 0.3016486316919327\n",
      "loss: 0.3025483787059784\n",
      "loss: 0.2987814426422119\n",
      "loss: 0.29642883539199827\n",
      "loss: 0.2971513390541077\n",
      "loss: 0.29881748259067537\n",
      "loss: 0.29664705097675326\n",
      "loss: 0.29827080070972445\n",
      "loss: 0.299156129360199\n",
      "loss: 0.2952775567770004\n",
      "loss: 0.2981361269950867\n",
      "loss: 0.2959827154874802\n",
      "loss: 0.2933134824037552\n",
      "loss: 0.29596310555934907\n",
      "loss: 0.29573931992053987\n",
      "loss: 0.2913478761911392\n",
      "loss: 0.2938547879457474\n",
      "loss: 0.2924658805131912\n",
      "loss: 0.2888301193714142\n",
      "loss: 0.28717244863510133\n",
      "loss: 0.29184897541999816\n",
      "loss: 0.2911617547273636\n",
      "loss: 0.28687724471092224\n",
      "loss: 0.29022033512592316\n",
      "loss: 0.2844451040029526\n",
      "loss: 0.28380763828754424\n",
      "loss: 0.2881803423166275\n",
      "loss: 0.28111948668956754\n",
      "loss: 0.27812188267707827\n",
      "loss: 0.2770955443382263\n",
      "loss: 0.2748179346323013\n",
      "loss: 0.27219316065311433\n",
      "loss: 0.2728129953145981\n",
      "loss: 0.26955448985099795\n",
      "loss: 0.26739093065261843\n",
      "loss: 0.2702834725379944\n",
      "loss: 0.26873610317707064\n",
      "loss: 0.26109362542629244\n",
      "loss: 0.2610678642988205\n",
      "loss: 0.2666796952486038\n",
      "loss: 0.25818897783756256\n",
      "loss: 0.2568295806646347\n",
      "loss: 0.2577303797006607\n",
      "loss: 0.25628319978713987\n",
      "loss: 0.251461797952652\n",
      "loss: 0.257179793715477\n",
      "loss: 0.2566656440496445\n",
      "loss: 0.25264997482299806\n",
      "loss: 0.259833887219429\n",
      "loss: 0.2534119516611099\n",
      "loss: 0.2467205911874771\n",
      "loss: 0.25192711055278777\n",
      "loss: 0.24788451492786406\n",
      "loss: 0.24621521234512328\n",
      "loss: 0.2508168160915375\n",
      "loss: 0.24032073616981506\n",
      "loss: 0.24533633291721343\n",
      "loss: 0.23921819627285004\n",
      "loss: 0.23728951811790466\n",
      "loss: 0.23798929452896117\n",
      "loss: 0.23452971279621124\n",
      "loss: 0.23720116317272186\n",
      "loss: 0.23353034257888794\n",
      "loss: 0.23178007900714875\n",
      "loss: 0.23073360323905945\n",
      "loss: 0.22996408343315125\n",
      "loss: 0.22871007025241852\n",
      "loss: 0.23019661903381347\n",
      "loss: 0.22782046794891359\n",
      "loss: 0.22729917764663696\n",
      "loss: 0.22909748256206514\n",
      "loss: 0.22791720926761627\n",
      "loss: 0.22913117408752443\n",
      "loss: 0.22587264478206634\n",
      "loss: 0.2244398206472397\n",
      "loss: 0.22037722468376159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.21944119334220885\n",
      "loss: 0.21641429364681244\n",
      "loss: 0.2163900375366211\n",
      "loss: 0.21368127167224885\n",
      "loss: 0.21223822832107545\n",
      "loss: 0.21224642992019654\n",
      "loss: 0.2134406477212906\n",
      "loss: 0.21015147268772125\n",
      "loss: 0.21016659140586852\n",
      "loss: 0.211619234085083\n",
      "loss: 0.21015809178352357\n",
      "loss: 0.21265054643154144\n",
      "loss: 0.2115221858024597\n",
      "loss: 0.20753279328346252\n",
      "loss: 0.20657336115837097\n",
      "loss: 0.2085155129432678\n",
      "loss: 0.2087952733039856\n",
      "loss: 0.20818174183368682\n",
      "loss: 0.2117968827486038\n",
      "loss: 0.21058105528354645\n",
      "loss: 0.2073229283094406\n",
      "loss: 0.21580494940280914\n",
      "loss: 0.20881400406360626\n",
      "loss: 0.2097170054912567\n",
      "loss: 0.2021850675344467\n",
      "loss: 0.20223195254802703\n",
      "loss: 0.20116907954216004\n",
      "loss: 0.2012250989675522\n",
      "loss: 0.19731835424900054\n",
      "loss: 0.19894111454486846\n",
      "loss: 0.19922910630702972\n",
      "loss: 0.1961271196603775\n",
      "loss: 0.19574955403804778\n",
      "loss: 0.20119810998439788\n",
      "loss: 0.1984974503517151\n",
      "loss: 0.19914743900299073\n",
      "loss: 0.19828783273696898\n",
      "loss: 0.19830714762210847\n",
      "loss: 0.2017400085926056\n",
      "loss: 0.2015540599822998\n",
      "loss: 0.1971963882446289\n",
      "loss: 0.1965365916490555\n",
      "loss: 0.19749106764793395\n",
      "loss: 0.1936687409877777\n",
      "loss: 0.19534972012043\n",
      "loss: 0.19693372249603272\n",
      "loss: 0.19601309299468994\n",
      "loss: 0.19833228290081023\n",
      "loss: 0.19534409940242767\n",
      "loss: 0.19406106173992158\n",
      "loss: 0.19157617390155793\n",
      "loss: 0.19004201591014863\n",
      "loss: 0.18697724342346192\n",
      "loss: 0.18494594395160674\n",
      "loss: 0.18331704735755922\n",
      "loss: 0.18209637999534606\n",
      "loss: 0.18258472084999083\n",
      "loss: 0.18137727528810502\n",
      "loss: 0.17936401963233947\n",
      "loss: 0.17824754416942595\n",
      "loss: 0.17827683687210083\n",
      "loss: 0.17819095104932786\n",
      "loss: 0.17606793344020844\n",
      "loss: 0.17941521406173705\n",
      "loss: 0.17614116966724397\n",
      "loss: 0.17651601731777192\n",
      "loss: 0.17854786515235901\n",
      "loss: 0.18119614124298095\n",
      "loss: 0.17776721119880676\n",
      "loss: 0.18620095252990723\n",
      "loss: 0.19031513333320618\n",
      "loss: 0.18870937526226045\n",
      "loss: 0.18945383727550508\n",
      "loss: 0.18901111781597138\n",
      "loss: 0.1844582140445709\n",
      "loss: 0.19105423986911774\n",
      "loss: 0.19261083602905274\n",
      "loss: 0.19029050469398498\n",
      "loss: 0.19368408918380736\n",
      "loss: 0.18904027342796326\n",
      "loss: 0.18714879155158998\n",
      "loss: 0.1867634028196335\n",
      "loss: 0.1780706986784935\n",
      "loss: 0.1763358384370804\n",
      "loss: 0.17460801154375077\n",
      "loss: 0.17343858927488326\n",
      "loss: 0.17369873225688934\n",
      "loss: 0.1726256340742111\n",
      "loss: 0.17171286344528197\n",
      "loss: 0.17050278633832933\n",
      "loss: 0.17020745426416398\n",
      "loss: 0.16791852861642836\n",
      "loss: 0.1691816732287407\n",
      "loss: 0.16906656622886657\n",
      "loss: 0.16827820986509323\n",
      "loss: 0.16895682960748673\n",
      "loss: 0.16674531251192093\n",
      "loss: 0.16533562988042833\n",
      "loss: 0.16659803539514542\n",
      "loss: 0.16477449089288712\n",
      "loss: 0.1650739297270775\n",
      "loss: 0.16609385758638381\n",
      "loss: 0.16434517204761506\n",
      "loss: 0.16380909085273743\n",
      "loss: 0.16756121218204498\n",
      "loss: 0.16599337309598922\n",
      "loss: 0.16549128741025926\n",
      "loss: 0.16921140402555465\n",
      "loss: 0.16388361304998397\n",
      "loss: 0.16560887396335602\n",
      "loss: 0.1708863064646721\n",
      "loss: 0.16628923863172532\n",
      "loss: 0.16921126544475557\n",
      "loss: 0.16980476081371307\n",
      "loss: 0.16725463271141053\n",
      "loss: 0.17174443155527114\n",
      "loss: 0.17210644632577896\n",
      "loss: 0.16910240352153777\n",
      "loss: 0.1710403010249138\n",
      "loss: 0.16465769708156586\n",
      "loss: 0.17052146941423416\n",
      "loss: 0.16689545512199402\n",
      "loss: 0.16624204069375992\n",
      "loss: 0.1664182111620903\n",
      "loss: 0.16678196489810942\n",
      "loss: 0.16747591644525528\n",
      "loss: 0.16624457091093064\n",
      "loss: 0.16540340036153794\n",
      "loss: 0.16408058106899262\n",
      "loss: 0.16337658762931823\n",
      "loss: 0.1671547383069992\n",
      "loss: 0.16731338500976561\n",
      "loss: 0.16967368572950364\n",
      "loss: 0.16888953745365143\n",
      "loss: 0.17085180580615997\n",
      "loss: 0.17095101326704026\n",
      "loss: 0.1695002257823944\n",
      "loss: 0.16360062658786773\n",
      "loss: 0.16237173974514008\n",
      "loss: 0.1610967829823494\n",
      "loss: 0.15949042290449142\n",
      "loss: 0.15975174009799958\n",
      "loss: 0.15692196190357208\n",
      "loss: 0.15724695473909378\n",
      "loss: 0.15543351620435714\n",
      "loss: 0.15564650893211365\n",
      "loss: 0.15606193244457245\n",
      "loss: 0.155403533577919\n",
      "loss: 0.1547166660428047\n",
      "loss: 0.15407015532255172\n",
      "loss: 0.15459380447864532\n",
      "loss: 0.15460952371358871\n",
      "loss: 0.15582725107669831\n",
      "loss: 0.15362609475851058\n",
      "loss: 0.15392887890338897\n",
      "loss: 0.1549716666340828\n",
      "loss: 0.15477356165647507\n",
      "loss: 0.15457937270402908\n",
      "loss: 0.1557049795985222\n",
      "loss: 0.15600378215312957\n",
      "loss: 0.1558707445859909\n",
      "loss: 0.1578465983271599\n",
      "loss: 0.15367863178253174\n",
      "loss: 0.1558687284588814\n",
      "loss: 0.15827324241399765\n",
      "loss: 0.15394623577594757\n",
      "loss: 0.1561475545167923\n",
      "loss: 0.15437893569469452\n",
      "loss: 0.1527077943086624\n",
      "loss: 0.1564096748828888\n",
      "loss: 0.15302009731531144\n",
      "loss: 0.15412609726190568\n",
      "loss: 0.15825819224119186\n",
      "loss: 0.1535218358039856\n",
      "loss: 0.1586405947804451\n",
      "loss: 0.15747937560081482\n",
      "loss: 0.15567305386066438\n",
      "loss: 0.16160351037979126\n",
      "loss: 0.15186678618192673\n",
      "loss: 0.1558764860033989\n",
      "loss: 0.1540835529565811\n",
      "loss: 0.15278242230415345\n",
      "loss: 0.1562473565340042\n",
      "loss: 0.15553459972143174\n",
      "loss: 0.15438445210456847\n",
      "loss: 0.15573768615722655\n",
      "loss: 0.15695168673992158\n",
      "loss: 0.15921085625886916\n",
      "loss: 0.1582912474870682\n",
      "loss: 0.15688430666923522\n",
      "loss: 0.15583328753709794\n",
      "loss: 0.15823350101709366\n",
      "loss: 0.15585273802280425\n",
      "loss: 0.15345111936330796\n",
      "loss: 0.14941467791795732\n",
      "loss: 0.15074134320020677\n",
      "loss: 0.14920211732387542\n",
      "loss: 0.1482466369867325\n",
      "loss: 0.14892401844263076\n",
      "loss: 0.14566164016723632\n",
      "loss: 0.14677056521177292\n",
      "loss: 0.1446165233850479\n",
      "loss: 0.14427872002124786\n",
      "loss: 0.14583711326122284\n",
      "loss: 0.1438769891858101\n",
      "loss: 0.1448902428150177\n",
      "loss: 0.14387549906969072\n",
      "loss: 0.14230499863624574\n",
      "loss: 0.143980573117733\n",
      "loss: 0.1422628030180931\n",
      "loss: 0.14201121628284455\n",
      "loss: 0.143193319439888\n",
      "loss: 0.1420511081814766\n",
      "loss: 0.1437949314713478\n",
      "loss: 0.14374287724494933\n",
      "loss: 0.1409050777554512\n",
      "loss: 0.14527883380651474\n",
      "loss: 0.14259364306926728\n",
      "loss: 0.14458357244729997\n",
      "loss: 0.14588507264852524\n",
      "loss: 0.141833034157753\n",
      "loss: 0.14665712118148805\n",
      "loss: 0.14467545300722123\n",
      "loss: 0.1458764687180519\n",
      "loss: 0.14631547778844833\n",
      "loss: 0.14287230223417283\n",
      "loss: 0.14891866445541382\n",
      "loss: 0.14447450488805771\n",
      "loss: 0.1473521411418915\n",
      "loss: 0.14839436262845992\n",
      "loss: 0.1464020848274231\n",
      "loss: 0.1516336664557457\n",
      "loss: 0.14988255351781846\n",
      "loss: 0.14975303560495376\n",
      "loss: 0.14583279490470885\n",
      "loss: 0.14559075981378555\n",
      "loss: 0.14774246215820314\n",
      "loss: 0.1422982171177864\n",
      "loss: 0.14308609962463378\n",
      "loss: 0.1404220387339592\n",
      "loss: 0.14059607833623886\n",
      "loss: 0.1414898380637169\n",
      "loss: 0.13942231982946396\n",
      "loss: 0.13988896012306212\n",
      "loss: 0.13862990140914916\n",
      "loss: 0.13910746723413467\n",
      "loss: 0.14002675116062163\n",
      "loss: 0.137871091067791\n",
      "loss: 0.1380733922123909\n",
      "loss: 0.13696200847625734\n",
      "loss: 0.13723817765712737\n",
      "loss: 0.13774332255125046\n",
      "loss: 0.1369863897562027\n",
      "loss: 0.13721025884151458\n",
      "loss: 0.13745809197425843\n",
      "loss: 0.13633332550525665\n",
      "loss: 0.13732121586799623\n",
      "loss: 0.13599836230278015\n",
      "loss: 0.1364928215742111\n",
      "loss: 0.13739192485809326\n",
      "loss: 0.13597991615533828\n",
      "loss: 0.13890375047922135\n",
      "loss: 0.13715968430042266\n",
      "loss: 0.13951185941696168\n",
      "loss: 0.1408640131354332\n",
      "loss: 0.13755334317684173\n",
      "loss: 0.13996647894382477\n",
      "loss: 0.13840027749538422\n",
      "loss: 0.13814785182476044\n",
      "loss: 0.13985302895307541\n",
      "loss: 0.13811082988977433\n",
      "loss: 0.1379968300461769\n",
      "loss: 0.14275070428848266\n",
      "loss: 0.13786776959896088\n",
      "loss: 0.14047903418540955\n",
      "loss: 0.13987330794334413\n",
      "loss: 0.13935195803642272\n",
      "loss: 0.14803439974784852\n",
      "loss: 0.14029261320829392\n",
      "loss: 0.14277733713388444\n",
      "loss: 0.13947660475969315\n",
      "loss: 0.13867909014225005\n",
      "loss: 0.14184596091508866\n",
      "loss: 0.1366982027888298\n",
      "loss: 0.1398767724633217\n",
      "loss: 0.13589272648096085\n",
      "loss: 0.13608667701482774\n",
      "loss: 0.13703741878271103\n",
      "loss: 0.13511399030685425\n",
      "loss: 0.13768001049757003\n",
      "loss: 0.13392646610736847\n",
      "loss: 0.13675440102815628\n",
      "loss: 0.1383901983499527\n",
      "loss: 0.1389777421951294\n",
      "loss: 0.14350622445344924\n",
      "loss: 0.13512607514858246\n",
      "loss: 0.1387931928038597\n",
      "loss: 0.13584864586591722\n",
      "loss: 0.13856000304222107\n",
      "loss: 0.1405412197113037\n",
      "loss: 0.13827280700206757\n",
      "loss: 0.13934511691331863\n",
      "loss: 0.13648835718631744\n",
      "loss: 0.13910330086946487\n",
      "loss: 0.13867004811763764\n",
      "loss: 0.1363410845398903\n",
      "loss: 0.13720230460166932\n",
      "loss: 0.1333017259836197\n",
      "loss: 0.13502926826477052\n",
      "loss: 0.13453107476234435\n",
      "loss: 0.1352207452058792\n",
      "loss: 0.13436577022075652\n",
      "loss: 0.13238698989152908\n",
      "loss: 0.13318341970443726\n",
      "loss: 0.13213415443897247\n",
      "loss: 0.13368373215198517\n",
      "loss: 0.13247184008359908\n",
      "loss: 0.13041126132011413\n",
      "loss: 0.1314996749162674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.13041398376226426\n",
      "loss: 0.13220637291669846\n",
      "loss: 0.13187080174684523\n",
      "loss: 0.13275076746940612\n",
      "loss: 0.1332360103726387\n",
      "loss: 0.13213045597076417\n",
      "loss: 0.13474689573049545\n",
      "loss: 0.134626667201519\n",
      "loss: 0.13082030266523362\n",
      "loss: 0.13075461536645888\n",
      "loss: 0.1281462401151657\n",
      "loss: 0.12764533013105392\n",
      "loss: 0.12821342051029205\n",
      "loss: 0.1271494671702385\n",
      "loss: 0.12844094783067703\n",
      "loss: 0.12761468887329103\n",
      "loss: 0.12704060226678848\n",
      "loss: 0.1294735088944435\n",
      "loss: 0.12781810462474824\n",
      "loss: 0.12810629606246948\n",
      "loss: 0.1281293272972107\n",
      "loss: 0.12765832543373107\n",
      "loss: 0.1295992374420166\n",
      "loss: 0.1298574134707451\n",
      "loss: 0.12956509590148926\n",
      "loss: 0.13009819835424424\n",
      "loss: 0.1289130002260208\n",
      "loss: 0.1307766392827034\n",
      "loss: 0.13017017990350724\n",
      "loss: 0.13169043362140656\n",
      "loss: 0.13280769139528276\n",
      "loss: 0.1316063940525055\n",
      "loss: 0.13438787311315536\n",
      "loss: 0.1327378734946251\n",
      "loss: 0.12973684072494507\n",
      "loss: 0.1317090019583702\n",
      "loss: 0.12912764847278596\n",
      "loss: 0.1287749320268631\n",
      "loss: 0.12953146249055864\n",
      "loss: 0.12798197120428084\n",
      "loss: 0.13066047579050064\n",
      "loss: 0.1276690199971199\n",
      "loss: 0.12896135002374648\n",
      "loss: 0.1295525461435318\n",
      "loss: 0.1283583238720894\n",
      "loss: 0.13180377334356308\n",
      "loss: 0.12794095575809478\n",
      "loss: 0.12894482761621476\n",
      "loss: 0.13015235662460328\n",
      "loss: 0.12850823104381562\n",
      "loss: 0.12988289594650268\n",
      "loss: 0.12700869441032409\n",
      "loss: 0.1291782408952713\n",
      "loss: 0.12782997488975525\n",
      "loss: 0.12688025534152986\n",
      "loss: 0.1286330431699753\n",
      "loss: 0.12458135485649109\n",
      "loss: 0.12703501731157302\n",
      "loss: 0.12621820718050003\n",
      "loss: 0.1268168345093727\n",
      "loss: 0.12814927399158477\n",
      "loss: 0.12556479275226592\n",
      "loss: 0.1275910884141922\n",
      "loss: 0.12607549130916595\n",
      "loss: 0.12752042412757875\n",
      "loss: 0.12544600963592528\n",
      "loss: 0.12452098578214646\n",
      "loss: 0.1252998024225235\n",
      "loss: 0.12602418661117554\n",
      "loss: 0.12809264957904815\n",
      "loss: 0.12518849223852158\n",
      "loss: 0.12868524640798568\n",
      "loss: 0.12674879729747773\n",
      "loss: 0.12635644525289536\n",
      "loss: 0.12492052614688873\n",
      "loss: 0.12356653064489365\n",
      "loss: 0.12675259560346602\n",
      "loss: 0.12344062924385071\n",
      "loss: 0.12497071027755738\n",
      "loss: 0.12213757932186127\n",
      "loss: 0.12211285084486008\n",
      "loss: 0.12257596403360367\n",
      "loss: 0.12179789692163467\n",
      "loss: 0.12311109006404877\n",
      "loss: 0.12030363827943802\n",
      "loss: 0.12213518172502517\n",
      "loss: 0.12118775844573974\n",
      "loss: 0.12212092876434326\n",
      "loss: 0.1234525740146637\n",
      "loss: 0.12120298892259598\n",
      "loss: 0.12435490638017654\n",
      "loss: 0.12118104249238967\n",
      "loss: 0.1232943594455719\n",
      "loss: 0.12158556282520294\n",
      "loss: 0.12317868620157242\n",
      "loss: 0.12787045687437057\n",
      "loss: 0.12187097519636154\n",
      "loss: 0.12534867227077484\n",
      "loss: 0.12199372798204422\n",
      "loss: 0.12328853458166122\n",
      "loss: 0.12540157586336137\n",
      "loss: 0.12404090464115143\n",
      "loss: 0.12657662183046342\n",
      "loss: 0.12233884036540985\n",
      "loss: 0.12493283897638321\n",
      "loss: 0.12398061007261277\n",
      "loss: 0.12498383224010468\n",
      "loss: 0.12474382221698761\n",
      "loss: 0.12281862795352935\n",
      "loss: 0.12293022572994232\n",
      "loss: 0.12292429953813552\n",
      "loss: 0.12386335283517838\n",
      "loss: 0.12242605090141297\n",
      "loss: 0.12410690188407898\n",
      "loss: 0.1218668833374977\n",
      "loss: 0.12427587211132049\n",
      "loss: 0.12302882373332977\n",
      "loss: 0.12227442562580108\n",
      "loss: 0.12476990073919296\n",
      "loss: 0.12296692430973052\n",
      "loss: 0.12165834307670594\n",
      "loss: 0.11990973055362701\n",
      "loss: 0.11938077807426453\n",
      "loss: 0.1193153589963913\n",
      "loss: 0.1199551522731781\n",
      "loss: 0.12012076675891876\n",
      "loss: 0.11861111372709274\n",
      "loss: 0.11876658052206039\n",
      "loss: 0.11848946809768676\n",
      "loss: 0.11829194575548171\n",
      "loss: 0.11878388822078705\n",
      "loss: 0.11829256117343903\n",
      "loss: 0.11717620342969895\n",
      "loss: 0.11600332260131836\n",
      "loss: 0.11530323773622513\n",
      "loss: 0.11544833183288575\n",
      "loss: 0.11532164514064788\n",
      "loss: 0.11607308983802796\n",
      "loss: 0.11586621850728988\n",
      "loss: 0.11632202118635178\n",
      "loss: 0.11683136224746704\n",
      "loss: 0.1173727348446846\n",
      "loss: 0.1178466260433197\n",
      "loss: 0.11733175218105316\n",
      "loss: 0.11575522869825364\n",
      "loss: 0.11677051782608032\n",
      "loss: 0.11591348499059677\n",
      "loss: 0.11643700003623962\n",
      "loss: 0.11741310805082321\n",
      "loss: 0.11624114513397217\n",
      "loss: 0.11745885312557221\n",
      "loss: 0.11758902966976166\n",
      "loss: 0.11667090356349945\n",
      "loss: 0.12076907753944396\n",
      "loss: 0.11770519614219666\n",
      "loss: 0.11991874426603318\n",
      "loss: 0.12020139992237092\n",
      "loss: 0.11987599432468414\n",
      "loss: 0.1230319619178772\n",
      "loss: 0.12141123116016388\n",
      "loss: 0.12315293848514557\n",
      "loss: 0.12506499588489534\n",
      "loss: 0.12325077056884766\n",
      "loss: 0.12778245955705642\n",
      "loss: 0.12465527951717377\n",
      "loss: 0.12224740386009217\n",
      "loss: 0.12248569279909134\n",
      "loss: 0.12282314896583557\n",
      "loss: 0.12488078773021698\n",
      "loss: 0.12336435765028\n",
      "loss: 0.12318388670682907\n",
      "loss: 0.12268783152103424\n",
      "loss: 0.12604850083589553\n",
      "loss: 0.1306234657764435\n",
      "loss: 0.1279037445783615\n",
      "loss: 0.12849846482276917\n",
      "loss: 0.1244942381978035\n",
      "loss: 0.1229444071650505\n",
      "loss: 0.12323525100946427\n",
      "loss: 0.12196757346391678\n",
      "loss: 0.12108929008245468\n",
      "loss: 0.1191547080874443\n",
      "loss: 0.11766473799943925\n",
      "loss: 0.1169154942035675\n",
      "loss: 0.11629291772842407\n",
      "loss: 0.11535745859146118\n",
      "loss: 0.11511834412813186\n",
      "loss: 0.11370697915554047\n",
      "loss: 0.11447310447692871\n",
      "loss: 0.11546074450016022\n",
      "loss: 0.11507216840982437\n",
      "loss: 0.11495875865221024\n",
      "loss: 0.11334620863199234\n",
      "loss: 0.11396525055170059\n",
      "loss: 0.11379661560058593\n",
      "loss: 0.1135207623243332\n",
      "loss: 0.11282379925251007\n",
      "loss: 0.11201132535934448\n",
      "loss: 0.11200334131717682\n",
      "loss: 0.11149433851242066\n",
      "loss: 0.11187954246997833\n",
      "loss: 0.11181579977273941\n",
      "loss: 0.11080942451953887\n",
      "loss: 0.11131100952625275\n",
      "loss: 0.1108822539448738\n",
      "loss: 0.11138429641723632\n",
      "loss: 0.1120106041431427\n",
      "loss: 0.11071325987577438\n",
      "loss: 0.11211318075656891\n",
      "loss: 0.11208159029483795\n",
      "loss: 0.11251208782196045\n",
      "loss: 0.11401967108249664\n",
      "loss: 0.11298215687274933\n",
      "loss: 0.11276411712169647\n",
      "loss: 0.11496457755565644\n",
      "loss: 0.11328783631324768\n",
      "loss: 0.11529674530029296\n",
      "loss: 0.11604989171028138\n",
      "loss: 0.11318316906690598\n",
      "loss: 0.11813261806964874\n",
      "loss: 0.11429090350866318\n",
      "loss: 0.1173158273100853\n",
      "loss: 0.11890246570110322\n",
      "loss: 0.11477913707494736\n",
      "loss: 0.12086488455533981\n",
      "loss: 0.11449384093284606\n",
      "loss: 0.11893965303897858\n",
      "loss: 0.11855052411556244\n",
      "loss: 0.11801827102899551\n",
      "loss: 0.12117176502943039\n",
      "loss: 0.11671003699302673\n",
      "loss: 0.11930431574583053\n",
      "loss: 0.1171296164393425\n",
      "loss: 0.11976256668567657\n",
      "loss: 0.11796173602342605\n",
      "loss: 0.11651757508516311\n",
      "loss: 0.11494413912296295\n",
      "loss: 0.11526950150728225\n",
      "loss: 0.11635550558567047\n",
      "loss: 0.1146579310297966\n",
      "loss: 0.11578843593597413\n",
      "loss: 0.1122648760676384\n",
      "loss: 0.11175617575645447\n",
      "loss: 0.11143647730350495\n",
      "loss: 0.11026239395141602\n",
      "loss: 0.11011313498020173\n",
      "loss: 0.10947306752204895\n",
      "loss: 0.1097167357802391\n",
      "loss: 0.10949446260929108\n",
      "loss: 0.10932983756065369\n",
      "loss: 0.10927406698465347\n",
      "loss: 0.10920312404632568\n",
      "loss: 0.11071363091468811\n",
      "loss: 0.11032647639513016\n",
      "loss: 0.10972183793783188\n",
      "loss: 0.10904159247875214\n",
      "loss: 0.10895238369703293\n",
      "loss: 0.10957358181476592\n",
      "loss: 0.10903863757848739\n",
      "loss: 0.10870812237262725\n",
      "loss: 0.10832201540470124\n",
      "loss: 0.108152075111866\n",
      "loss: 0.10906099677085876\n",
      "loss: 0.1085162416100502\n",
      "loss: 0.10906016379594803\n",
      "loss: 0.10883118212223053\n",
      "loss: 0.1086645856499672\n",
      "loss: 0.10932070165872573\n",
      "loss: 0.10924451351165772\n",
      "loss: 0.10897791981697083\n",
      "loss: 0.10864481776952743\n",
      "loss: 0.10995015352964402\n",
      "loss: 0.10872558802366257\n",
      "loss: 0.11079098135232926\n",
      "loss: 0.11116345673799514\n",
      "loss: 0.11098762154579163\n",
      "loss: 0.115065698325634\n",
      "loss: 0.11355913430452347\n",
      "loss: 0.11385931521654129\n",
      "loss: 0.11564634889364242\n",
      "loss: 0.11505422890186309\n",
      "loss: 0.11702964156866073\n",
      "loss: 0.11719908714294433\n",
      "loss: 0.11822687089443207\n",
      "loss: 0.12233839482069016\n",
      "loss: 0.12352333664894104\n",
      "loss: 0.12310715019702911\n",
      "loss: 0.12135367691516877\n",
      "loss: 0.1198171079158783\n",
      "loss: 0.12273628711700439\n",
      "loss: 0.12183374762535096\n",
      "loss: 0.12501306980848312\n",
      "loss: 0.12648877501487732\n",
      "loss: 0.12681631445884706\n",
      "loss: 0.12563060373067855\n",
      "loss: 0.12606087774038316\n",
      "loss: 0.13333911448717117\n",
      "loss: 0.13927904963493348\n",
      "loss: 0.13990938514471055\n",
      "loss: 0.13020867705345154\n",
      "loss: 0.12912192344665527\n",
      "loss: 0.1195988804101944\n",
      "loss: 0.11817248910665512\n",
      "loss: 0.11341492235660552\n",
      "loss: 0.11377186328172684\n",
      "loss: 0.11147270500659942\n",
      "loss: 0.11263906359672546\n",
      "loss: 0.10962155312299729\n",
      "loss: 0.11101661622524261\n",
      "loss: 0.11210097670555115\n",
      "loss: 0.11284859478473663\n",
      "loss: 0.1123778223991394\n",
      "loss: 0.11113026440143585\n",
      "loss: 0.11321133375167847\n",
      "loss: 0.10915362238883972\n",
      "loss: 0.1097625270485878\n",
      "loss: 0.10715346783399582\n",
      "loss: 0.10677840560674667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.10700096487998963\n",
      "loss: 0.10667206197977067\n",
      "loss: 0.10638737231492996\n",
      "loss: 0.10570160150527955\n",
      "loss: 0.10576317757368088\n",
      "loss: 0.10494960695505143\n",
      "loss: 0.10518445968627929\n",
      "loss: 0.10432399362325669\n",
      "loss: 0.10457066893577575\n",
      "loss: 0.10468761175870896\n",
      "loss: 0.10416443049907684\n",
      "loss: 0.10445534586906433\n",
      "loss: 0.10424883812665939\n",
      "loss: 0.10421891063451767\n",
      "loss: 0.10414347052574158\n",
      "loss: 0.10418057292699814\n",
      "loss: 0.10390780121088028\n",
      "loss: 0.10358244478702545\n",
      "loss: 0.10330913066864014\n",
      "loss: 0.1043105110526085\n",
      "loss: 0.10566964745521545\n",
      "loss: 0.10568356215953827\n",
      "loss: 0.1056232824921608\n",
      "loss: 0.10434226989746094\n",
      "loss: 0.10576246082782745\n",
      "loss: 0.10705870985984803\n",
      "loss: 0.10787830799818039\n",
      "loss: 0.108588607609272\n",
      "loss: 0.10704617202281952\n",
      "loss: 0.10795335024595261\n",
      "loss: 0.10728948712348937\n",
      "loss: 0.10681288689374924\n",
      "loss: 0.10797723978757859\n",
      "loss: 0.1064338818192482\n",
      "loss: 0.10706541091203689\n",
      "loss: 0.10713682025671005\n",
      "loss: 0.10825761556625366\n",
      "loss: 0.11143080443143845\n",
      "loss: 0.10959194898605347\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "valid_loss = []\n",
    "for e in range(1000):\n",
    "    for phase in [\"train\", \"valid\"]:\n",
    "        total = []\n",
    "        for model_ids, visuals, captions, cap_lengths in dataloader[phase]:\n",
    "            inputs = Variable(visuals)\n",
    "            caption_inputs = Variable(torch.cat([item.view(1, -1) for item in captions]).transpose(1, 0)[:, :cap_lengths[0]])\n",
    "            outputs = model(inputs, caption_inputs)\n",
    "            loss = cr(outputs, visuals)\n",
    "            if phase == \"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            total.append(loss.item())\n",
    "        if phase == \"train\":\n",
    "            print(\"{}_loss:\".format(phase), np.mean(total))\n",
    "            train_loss.append(np.mean(total))\n",
    "        else:\n",
    "            print(\"{}_loss:\".format(phase), np.mean(total))\n",
    "            valid_loss.append(np.mean(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
