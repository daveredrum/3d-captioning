{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas \n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import operator\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from data import *\n",
    "from constants import *\n",
    "from models import *\n",
    "from solver import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/mnt/raid/davech2y/3d_captioning/ShapeNetCore_vol/nrrd_256_filter_div_128_solid/\"\n",
    "captions = pandas.read_csv(\"captions.tablechair.csv\").iloc[:600]\n",
    "visual_contexts = np.load(\"data/visual_context.npy\")\n",
    "# captions = pandas.read_csv(\"captions.tablechair_prep.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions = Caption(captions)\n",
    "captions.preprocess()\n",
    "captions.tranform()\n",
    "captions.sanity_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_captions = captions.tranformed_csv.iloc[:500]\n",
    "valid_captions = captions.tranformed_csv.iloc[500:600].reset_index(drop=True)\n",
    "train_context = visual_contexts[:500]\n",
    "valid_context = visual_contexts[500:600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "#                                                                 #\n",
    "#                                                                 #\n",
    "#                  offline training for encoder                   #\n",
    "#                                                                 #\n",
    "#                                                                 #\n",
    "###################################################################\n",
    "\n",
    "# shape_tranform = transforms.Compose([transforms.Resize(IMAGE_SIZE), transforms.ToTensor()])\n",
    "# shape_train_ds = ShapeDataset(root, train_captions, shape_tranform)\n",
    "# shape_train_dl = DataLoader(shape_train_ds, batch_size=10)\n",
    "# shape_valid_ds = ShapeDataset(root, valid_captions, shape_tranform)\n",
    "# shape_valid_dl = DataLoader(shape_valid_ds, batch_size=10)\n",
    "# shape_dl = {\n",
    "#     'train': shape_train_dl,\n",
    "#     'valid': shape_valid_dl\n",
    "# }\n",
    "\n",
    "# model = Encoder().cuda()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# encoder_solver = EncoderSolver(optimizer, criterion)\n",
    "\n",
    "# encoder_solver.train(model, shape_dl, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "#                                                                 #\n",
    "#                                                                 #\n",
    "#                  offline training for decoder                   #\n",
    "#              (extracted visual contexts required)               #\n",
    "#                                                                 #\n",
    "###################################################################\n",
    "\n",
    "# caption_train_ds = CaptionDataset(train_context, train_captions.description.values.tolist())\n",
    "# caption_train_dl = DataLoader(caption_train_ds, batch_size=50, shuffle=False)\n",
    "# caption_valid_ds = CaptionDataset(valid_context, valid_captions.description.values.tolist())\n",
    "# caption_valid_dl = DataLoader(caption_valid_ds, batch_size=50, shuffle=False)\n",
    "# caption_dl = {\n",
    "#     \"train\": caption_train_dl,\n",
    "#     \"valid\": caption_valid_dl\n",
    "# }\n",
    "\n",
    "# input_size = captions.dict_word2idx.__len__() + 1\n",
    "# hidden_size = 512\n",
    "# num_layer = 2\n",
    "# decoder = Decoder(input_size, hidden_size, 2).cuda()\n",
    "\n",
    "# decoder_solver = DecoderSolver(optim.RMSprop(decoder.parameters(), lr=0.001), nn.CrossEntropyLoss())\n",
    "\n",
    "# decoder_solver.train(decoder, caption_dl, 10000, 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
